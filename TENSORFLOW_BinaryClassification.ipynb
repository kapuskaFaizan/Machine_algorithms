{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TENSORFLOW-store-serialized-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapuskaFaizan/Machine_algorithms/blob/master/TENSORFLOW_BinaryClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqg47af_GiVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "9e172160-7f4c-483b-915c-3278aa181c75"
      },
      "source": [
        "#if keras is not installed use the following command to install\n",
        "!pip install --upgrade keras==2.2.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzbhrvCqGiVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "03b7bfaa-9d14-4aef-ab35-9b5dff336041"
      },
      "source": [
        "import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
            "  return f(*args, **kwds)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5D-U9BuGiVr",
        "colab_type": "text"
      },
      "source": [
        "# Create a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfmYTL30GiVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5e86fa61-25f6-4a60-cd5f-d6a6a687a05b"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "import pandas as pd\n",
        "X, y = make_moons(n_samples=500, noise=0.1)\n",
        "xdf=pd.DataFrame(X,columns=['f1','f2'])\n",
        "ydf=pd.DataFrame(y,columns=['label'])\n",
        "display(xdf.head(5))\n",
        "display(ydf.head(5))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.766858</td>\n",
              "      <td>0.428614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.170623</td>\n",
              "      <td>1.084345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.543018</td>\n",
              "      <td>0.939197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.156495</td>\n",
              "      <td>0.057413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.910524</td>\n",
              "      <td>0.186404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         f1        f2\n",
              "0  0.766858  0.428614\n",
              "1  0.170623  1.084345\n",
              "2 -0.543018  0.939197\n",
              "3  0.156495  0.057413\n",
              "4  0.910524  0.186404"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label\n",
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      1\n",
              "4      0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNWeVuIwHbd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "027ec598-f1d5-4763-9d35-7c1457c7a985"
      },
      "source": [
        "xdf.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXSq6DISGiV0",
        "colab_type": "text"
      },
      "source": [
        "# Create a keras | TENSORFLOW model\n",
        "\n",
        "NN with 50 nodes in a hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPaRJo9NL7xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow==1.4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNFuVKUbIkAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "# Initialize placeholders \n",
        "x = tf.placeholder(dtype = tf.float32, shape = [None, 2])\n",
        "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
        "\n",
        "# Flatten the input data\n",
        "images_flat = tf.contrib.layers.flatten(x)\n",
        "\n",
        "# Fully connected layer \n",
        "logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)\n",
        "\n",
        "# Define a loss function\n",
        "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, \n",
        "                                                                    logits = logits))\n",
        "# Define an optimizer \n",
        "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
        "\n",
        "# Convert logits to label indexes\n",
        "correct_pred = tf.argmax(logits, 1)\n",
        "\n",
        "# Define an accuracy metric\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAz5TCgoIkC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x ,test_x,train_y,test_y = train_test_split(xdf,ydf,test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg5etLdEIkFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ce84d20-5501-4153-af6d-63eb6e6fff4d"
      },
      "source": [
        "feature_count = train_x.shape[1]\n",
        "label_count = train_y.shape[1]\n",
        "print(feature_count, label_count)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RfF91GfIkID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inputs\n",
        "import numpy as np\n",
        "\n",
        "training_epochs = 3000\n",
        "learning_rate = 0.01\n",
        "hidden_layers = feature_count - 1\n",
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "\n",
        "X = tf.placeholder(tf.float32,[None,feature_count])\n",
        "Y = tf.placeholder(tf.float32,[None,label_count])\n",
        "is_training=tf.Variable(True,dtype=tf.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT63S8vAIkP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# models\n",
        "\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "h0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "# h0 = tf.nn.dropout(h0, 0.95)\n",
        "h1 = tf.layers.dense(h0, label_count, activation=None)\n",
        "\n",
        "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)\n",
        "cost = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# prediction = tf.argmax(h0, 1)\n",
        "# correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
        "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "predicted = tf.nn.sigmoid(h1)\n",
        "correct_pred = tf.equal(tf.round(predicted), Y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06uNhTZIkS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e8e72b5-32ad-4674-a9d0-58f00ee90837"
      },
      "source": [
        "# session\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(training_epochs + 1):\n",
        "        sess.run(optimizer, feed_dict={X: train_x, Y: train_y})\n",
        "        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n",
        "                                 X: train_x, Y: train_y})\n",
        "        cost_history = np.append(cost_history, acc)\n",
        "        if step % 500 == 0:\n",
        "            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n",
        "                step, loss, acc))\n",
        "            \n",
        "    # Test model and check accuracy\n",
        "    print('Test Accuracy:', sess.run([accuracy, tf.round(predicted)], feed_dict={X: test_x, Y: test_y}))\n",
        "    \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step:     0\tLoss: 0.831\tAcc: 31.34%\n",
            "Step:   500\tLoss: 0.261\tAcc: 87.76%\n",
            "Step:  1000\tLoss: 0.260\tAcc: 87.76%\n",
            "Step:  1500\tLoss: 0.260\tAcc: 87.76%\n",
            "Step:  2000\tLoss: 0.260\tAcc: 87.76%\n",
            "Step:  2500\tLoss: 0.260\tAcc: 87.76%\n",
            "Step:  3000\tLoss: 0.260\tAcc: 87.76%\n",
            "Test Accuracy: [0.8848485, array([[1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [1.],\n",
            "       [0.],\n",
            "       [1.],\n",
            "       [1.]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSPJTaxIkOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqw7rlcGIkLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b48VYM-GiV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0328f889-f19b-4668-fa42-3cb0bdbc1e74"
      },
      "source": [
        "'''\n",
        "#from keras.models import Sequential\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(50, input_dim=2, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#from keras.models import Sequential\\nmodel = keras.Sequential()\\nmodel.add(keras.layers.Dense(50, input_dim=2, activation='relu'))\\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1_avtDvGiV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e19bede-203e-4b41-fcad-f67ce4c16122"
      },
      "source": [
        "'''\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#train\n",
        "model.fit(xdf, ydf, epochs=10)\n",
        "'''"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n#train\\nmodel.fit(xdf, ydf, epochs=10)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}